<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
    <!-- Replace the content tag with appropriate information -->
    <meta name="description" content="DESCRIPTION META TAG">
    <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
    <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
    <meta property="og:url" content="URL OF THE WEBSITE"/>
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
    <meta property="og:image" content="static/image/your_banner_image.png"/>
    <meta property="og:image:width" content="1200"/>
    <meta property="og:image:height" content="630"/>


    <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
    <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
    <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
    <meta name="twitter:card" content="summary_large_image">
    <!-- Keywords for your paper to be indexed by-->
    <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <title>OpenDriveVLA: Towards End-to-end Autonomous Driving with Large Vision Language Action Model</title>
    <!-- <link rel="icon" type="image/x-icon" href="static/images/favicon.ico"> -->
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="static/css/bulma.min.css">
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="static/css/index.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
    <script defer src="static/js/fontawesome.all.min.js"></script>
    <script src="static/js/bulma-carousel.min.js"></script>
    <script src="static/js/bulma-slider.min.js"></script>
    <script src="static/js/index.js"></script>
</head>

<body>


<section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-4 publication-title">OpenDriveVLA: Towards End-to-end Autonomous Driving <br> with Large Vision Language Action Model</h1>
                    <div class="is-size-5 publication-authors">
                        <span class="author-block" style="margin-right: 15px;"><a href="https://scholar.google.com/citations?user=FPYXLpQAAAAJ&hl=en"
                                                          target="_blank">Xingcheng Zhou</a><sup>1*</sup>,</span>
                        <span class="author-block" style="margin-right: 15px;"><a href="https://scholar.google.com/citations?hl=en&user=LQPhI6AAAAAJ"
                                                      target="_blank">Xuyuan Han</a><sup>1</sup>,</span>
                        <span class="author-block" style="margin-right: 15px;"><a href="https://www.linkedin.com/in/feng-yang-tum/"
                                                      target="_blank">Feng Yang</a><sup>1</sup>,</span>
                        <span class="author-block" style="margin-right: 15px;"><a href="https://scholar.google.com/citations?user=fj5DzgcAAAAJ&hl=en" target="_blank">Yunpu Ma </a><sup>2</sup>,</span>
                        <span class="author-block"><a
                                href="https://www.ce.cit.tum.de/air/people/prof-dr-ing-habil-alois-knoll"
                                target="_blank">Alois C. Knoll</a><sup>1</sup></span>
                    </div>

                    <div class="is-size-5 publication-authors">
                        <span class="author-block" style="margin-right: 5px;"><sup>1</sup>Technical University of Munich</span>
                        <span class="author-block"><br><sup>2</sup>Ludwig Maximilian University of Munich</span>
                        <span class="eql-cntrb"><small><br><sup>*</sup>Corresponding Author</small></span>
                    </div>

                    <div class="column has-text-centered">
                        <div class="publication-links">

                            <!-- Github link -->
                            <span class="link-block">
                                    <a href="https://github.com/DriveVLA/OpenDriveVLA" target="_blank"
                                       class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code</span>
                                    </a>
                                </span>

                            <!-- Arxiv link -->
                            <span class="link-block">
                                    <a href="https://arxiv.org/"
                                        target="_blank" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Arxiv</span>
                                    </a>
                                </span>

                            <!-- Dataset link -->
                            <span class="link-block">
                                    <a href=""
                                       target="_blank" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fa fa-database"></i>
                                        </span>
                                        <span>Dataset</span>
                                    </a>
                                </span>

                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="section hero" style="margin-top: -20px;">
    <div class="container">
        <div class="columns">
            <div class="column is-centered has-text-centered">
                <h2 class="title is-3">Visualization 1</h2>

                <div class="item video1">
                    <video poster="" autoplay controls muted loop style="width: 100%; height: auto;">
                        <source src="static/videos/OpenDriveVLA-7B-vis1.mp4" type="video/mp4">
                    </video>
                    <h2 class="subtitle has-text-justify">
                        <h2 class="subtitle">
                            <p><b>Visualization Results of OpenDriveVLA-7B on nuScenes val-mini set with temperature 0 (deterministic).</b> </p>
                        </h2>
                    </h2>
                </div>

            </div>
        </div>
    </div>
</section>

<section class="section hero" style="margin-top: -20px;">
    <div class="container">
        <div class="columns">
            <div class="column is-centered has-text-centered">
                <h2 class="title is-3">Visualization 2</h2>

                <div class="item video1">
                    <video poster="" autoplay controls muted loop style="width: 100%; height: auto;">
                        <source src="static/videos/OpenDriveVLA-7B-vis2.mp4" type="video/mp4">
                    </video>
                    <h2 class="subtitle has-text-justify">
                        <h2 class="subtitle">
                            <p><b>Visualization Results of OpenDriveVLA-7B on nuScenes val set with temperature 0 (deterministic).</b> </p>
                        </h2>
                    </h2>
                </div>

            </div>
        </div>
    </div>
</section>

<section class="section hero" style="margin-top: -20px;">
    <div class="container">
        <div class="columns">
            <div class="column is-centered has-text-centered">
                <h2 class="title is-3">Visualization 3</h2>

                <div class="item video1">
                    <video poster="" autoplay controls muted loop style="width: 100%; height: auto;">
                        <source src="static/videos/OpenDriveVLA-7B-vis3.mp4" type="video/mp4">
                    </video>
                    <h2 class="subtitle has-text-justify">
                        <h2 class="subtitle">
                            <p><b>Visualization Results of OpenDriveVLA-7B on nuScenes val set with temperature 0 (deterministic).</p>
                        </h2>
                    </h2>
                </div>

            </div>
        </div>
    </div>
</section>


<section class="section hero">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Abstract</h2>
                <div class="content has-text-justified">
                    <p>
                        We present OpenDriveVLA, a Vision-Language Action (VLA) model designed for end-to-end autonomous driving. OpenDriveVLA builds upon open-source pre-trained large Vision-Language Models (VLMs) to generate reliable open-loop driving actions, conditioned on 3D environmental perception, ego vehicle states, and driver commands. To bridge the modality gap between driving visual representations and language embeddings, we propose a hierarchical vision-language alignment process, projecting both 2D and 3D structured visual tokens into a unified semantic space. Besides, OpenDriveVLA models the dynamic relationships between the ego vehicle, surrounding agents, and static road elements through an autoregressive agent-env-ego interaction process, ensuring both spatially and behaviorally informed trajectory planning. Extensive experiments on the nuScenes dataset demonstrate that OpenDriveVLA achieves state-of-the-art results across open-loop trajectory planning and driving-related question-answering tasks. Qualitative analyses further illustrate OpenDriveVLA's superior capability to follow high-level driving commands and robustly generate trajectories under challenging scenarios, highlighting its potential for next-generation end-to-end autonomous driving. We will release our code to facilitate further research in this domain.
                    </p>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="hero teaser">
    <div class="container is-max-desktop">
        <div class="hero-body">
            <div class="item">
                <h2 class="title is-3" style="text-align: center;">OpenDriveVLA Model Architecture</h2>
                <img src="images/drivevla-ModelArc.jpg" alt="DriveVLA Model Architecture"/>
                <h2 class="subtitle">
                    <!-- <b>Visualization of the labeled Accid3nD dataset</b>. -->
                </h2>
            </div>
        </div>
    </div>
</section>



<footer class="footer">
    <div class="container">
        <div class="columns is-centered">
            <div class="column is-8">
                <div class="content has-text-centered">
                    <p>
                        The <strong>OpenDriveVLA</strong> is licensed under <a
                            href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA
                        4.0</a>.
                    </p>
                </div>
            </div>
        </div>
    </div>
</footer>


</body>

</html>