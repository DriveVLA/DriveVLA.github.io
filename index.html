<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
    <!-- Replace the content tag with appropriate information -->
    <meta name="description" content="DESCRIPTION META TAG">
    <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
    <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
    <meta property="og:url" content="URL OF THE WEBSITE"/>
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
    <meta property="og:image" content="static/image/your_banner_image.png"/>
    <meta property="og:image:width" content="1200"/>
    <meta property="og:image:height" content="630"/>


    <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
    <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
    <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
    <meta name="twitter:card" content="summary_large_image">
    <!-- Keywords for your paper to be indexed by-->
    <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <title>Open-DriveVLA: Towards End-to-end Autonomous Driving with Large Vision Language Action Models</title>
    <!-- <link rel="icon" type="image/x-icon" href="static/images/favicon.ico"> -->
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="static/css/bulma.min.css">
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="static/css/index.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
    <script defer src="static/js/fontawesome.all.min.js"></script>
    <script src="static/js/bulma-carousel.min.js"></script>
    <script src="static/js/bulma-slider.min.js"></script>
    <script src="static/js/index.js"></script>
</head>

<body>


<section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-4 publication-title">Open-DriveVLA: Towards End-to-end Autonomous Driving with 
                        Large <br> Vision Language Action Model</h1>
                    <div class="is-size-5 publication-authors">
                        <span class="author-block" style="margin-right: 15px;"><a href="https://scholar.google.com/citations?user=FPYXLpQAAAAJ&hl=en"
                                                          target="_blank">Xingcheng Zhou</a><sup>1*</sup>,</span>
                        <span class="author-block" style="margin-right: 15px;"><a href="https://scholar.google.com/citations?hl=en&user=LQPhI6AAAAAJ"
                                                      target="_blank">Xuyuan Han</a><sup>1</sup>,</span>
                        <span class="author-block" style="margin-right: 15px;"><a href="https://www.linkedin.com/in/feng-yang-tum/"
                                                      target="_blank">Feng Yang</a><sup>1</sup>,</span>
                        <span class="author-block" style="margin-right: 15px;"><a href="https://scholar.google.com/citations?user=fj5DzgcAAAAJ&hl=en" target="_blank">Yunpu Ma </a><sup>2</sup>,</span>
                        <span class="author-block"><a
                                href="https://www.ce.cit.tum.de/air/people/prof-dr-ing-habil-alois-knoll"
                                target="_blank">Alois C. Knoll</a><sup>1</sup></span>
                    </div>

                    <div class="is-size-5 publication-authors">
                        <span class="author-block" style="margin-right: 5px;"><sup>1</sup>Technical University of Munich</span>
                        <span class="author-block"><br><sup>2</sup>Ludwig Maximilian University of Munich</span>
                        <span class="eql-cntrb"><small><br><sup>*</sup>Corresponding Author</small></span>
                    </div>

                    <div class="column has-text-centered">
                        <div class="publication-links">

                            <!-- Github link -->
                            <span class="link-block">
                                    <a href="https://github.com" target="_blank"
                                       class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Model</span>
                                    </a>
                                </span>

                            <!-- Arxiv link -->
                            <span class="link-block">
                                    <a href="https://arxiv.org/"
                                        target="_blank" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Arxiv</span>
                                    </a>
                                </span>

                            <!-- Dataset link -->
                            <span class="link-block">
                                    <a href=""
                                       target="_blank" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fa fa-database"></i>
                                        </span>
                                        <span>Dataset</span>
                                    </a>
                                </span>

                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="section hero" style="margin-top: -20px;">
    <div class="container">
        <div class="columns">
            <div class="column is-centered has-text-centered">
                <h2 class="title is-3">Visualizations</h2>

                <div class="item video1">
                    <video poster="" autoplay controls muted loop style="width: 100%; height: auto;">
                        <source src="static/videos/open-DriveVLA-3B-vis.mp4" type="video/mp4">
                    </video>
                    <h2 class="subtitle has-text-justify">
                        <h2 class="subtitle">
                            <p><b>Visualization Results of Open-DriveVLA-3B on nuScenes val-mini set.</b> The ego vehicle's planning action is generated with temperature 0 (deterministic), while the agent's multi-path trajectory prediction with temperature 0.1, producing 3 possible trajectories.</p>
                        </h2>
                    </h2>
                </div>

            </div>
        </div>
    </div>
</section>


<section class="section hero">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Abstract</h2>
                <div class="content has-text-justified">
                    <p>
                        We present Open-DriveVLA, a salable Vision-Language Action model designed for end-to-end autonomous driving. Open-DriveVLA builds upon pre-trained large Vision-Language Models (VLMs) to generate reliable driving trajectories, conditioned on 3D environmental perception, ego vehicle states, and driver commands. To bridge the modality gap between driving visual representations and language embeddings, we propose a hierarchical vision-language alignment module, projecting both 2D and 3D structured visual tokens into a unified semantic space. Besides, Open-DriveVLA models the dynamic relationships between the ego vehicle, surrounding agents, and static road elements through an autoregressive agent-ego-map interaction module, ensuring both spatially and behaviorally informed trajectory planning. Extensive experiments on the nuScenes dataset demonstrate that Open-DriveVLA achieves state-of-the-art results across open-loop trajectory planning and driving-related question-answering tasks. Qualitative analyses further illustrate Open-DriveVLA's superior capability to follow high-level driving commands and robustly generate trajectories under challenging scenarios, highlighting its potential for interpretable end-to-end autonomous driving.
                    </p>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="hero teaser">
    <div class="container is-max-desktop">
        <div class="hero-body">
            <div class="item">
                <h2 class="title is-3" style="text-align: center;">DriveVLA Model Architecture</h2>
                <img src="images/drivevla-ModelArc.jpg" alt="DriveVLA Model Architecture"/>
                <h2 class="subtitle">
                    <!-- <b>Visualization of the labeled Accid3nD dataset</b>. -->
                </h2>
            </div>
        </div>
    </div>
</section>



<footer class="footer">
    <div class="container">
        <div class="columns is-centered">
            <div class="column is-8">
                <div class="content has-text-centered">
                    <p>
                        The <strong>Open-DriveVLA</strong> is licensed under <a
                            href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA
                        4.0</a>.
                    </p>
                </div>
            </div>
        </div>
    </div>
</footer>


</body>

</html>